conference,title,abstract,keywords
IEEE Security and Privacy 2009,Wirelessly Pickpocketing a Mifare Classic Card,"The Mifare Classic is the most widely used contactless smartcard on the market. The stream cipher CRYPTO1 used by the classic has recently been reverse engineered and serious attacks have been proposed. The most serious of them retrieves a secret key in under a second. In order to clone a card, previously proposed attacks require that the adversary either has access to an eavesdropped communication session or executes a message-by-message man-in-the-middle attack between the victim and a legitimate reader. Although this is already disastrous from a cryptographic point of view, system integrators maintain that these attacks cannot be performed undetected.This paper proposes four attacks that can be executed by an adversary having only wireless access to just a card (and not to a legitimate reader). The most serious of them recovers a secret key in less than a second on ordinary hardware. Besides the cryptographic weaknesses, we exploit other weaknesses in the protocol stack. A vulnerability in the computation of parity bits allows an adversary to establish a side channel. Another vulnerability regarding nested authentications provides enough plaintext for a speedy known-plaintext attack.","cryptography, smart cards, Mifare classic card, contactless smartcard, stream cipher, CRYPTO1, eavesdropped communication session, message-by-message man-in-the-middle attack, speedy known-plaintext attack, Cryptography, Authentication, Radiofrequency identification, Cloning, Access protocols, Access control, Communication standards, Security, Privacy, Reverse engineering, RFID, Mifare Classic, side-channel attack, CRYPTO1, Contactless smartcard,"
IEEE Security and Privacy 2009,Plaintext Recovery Attacks against SSH,"This paper presents a variety of plaintext-recovering attacks against SSH. We implemented a proof of concept of our attacks against OpenSSH, where we can verifiably recover 14 bits of plaintext from an arbitrary block of ciphertext with probability 2-14 and 32 bits of plaintext from an arbitrary block of ciphertext with probability 2-18. These attacks assume the default configuration of a 128-bit block cipher operating in CBC mode. The paper explains why a combination of flaws in the basic design of SSH leads implementations such as OpenSSH to be open to our attacks, why current provable security results for SSH do not cover our attacks, and how the attacks can be prevented in practice.","cryptography, protocols, plaintext recovery attacks, OpenSSH, ciphertext arbitrary block, secure protocol suites, Cryptography, Information security, Internet, Privacy, Cryptographic protocols, Data mining, SSH, attack,"
IEEE Security and Privacy 2009,Exploiting Unix File-System Races via Algorithmic Complexity Attacks,"We defeat two proposed Unix file-system race condition defense mechanisms. First, we attack the probabilistic defense mechanism of Tsafrir, et al., published at USENIX FAST 2008. We then show that the same attack breaks the kernel-based dynamic race detector of Tsyrklevich and Yee, published at USENIX Security 2003. We then argue that all kernel-based dynamic race detectors must have a model of the programs they protect or provide imperfect protection. The techniques we develop for performing these attacks work on multiple Unix operating systems, on uni- and multi-processors, and are useful for exploiting most Unix file-system races. We conclude that programmers should use provably-secure methods for avoiding race conditions when accessing the file-system.","file organisation, security of data, Unix, Unix file-system race condition defense mechanisms, algorithmic complexity attacks, USENIX FAST 2008, kernel-based dynamic race detector, Unix operating systems, Protection, Detectors, Kernel, Operating systems, Security, Programming profession, Linux, Computer bugs, Privacy, Clocks,"
IEEE Security and Privacy 2009,Practical Mitigations for Timing-Based Side-Channel Attacks on Modern x86 Processors,"This paper studies and evaluates the extent to which automated compiler techniques can defend against timing-based side-channel attacks on modern x86 processors. We study how modern x86 processors can leak timing information through side-channels that relate to control flow and data flow. To eliminate key-dependent control flow and key-dependent timing behavior related to control flow, we propose the use of if-conversion in a compiler backend, and evaluate a proof-of-concept prototype implementation. Furthermore, we demonstrate two ways in which programs that lack key-dependent control flow and key-dependent cache behavior can still leak timing information on modern x86 implementations such as the Intel Core 2 Duo, and propose defense mechanisms against them.","data flow analysis, microprocessor chips, program compilers, security of data, modern x86 processors, timing-based side-channel attacks, automated compiler techniques, eliminate key-dependent control flow, data flow, key-dependent timing behavior, Intel Core 2 Duo, compiler backend, proof-of-concept prototype implementation, key-dependent cache behavior, Cryptography, Counting circuits, Timing, Automatic control, Hardware, Pipelines, Information security, Privacy, Information systems, Informatics,"
IEEE Security and Privacy 2009,Noninterference for a Practical DIFC-Based Operating System,"The Flume system is an implementation of decentralized information flow control (DIFC) at the operating system level. Prior work has shown Flume can be implemented as a practical extension to the Linux operating system, allowing real Web applications to achieve useful security guarantees. However, the question remains if the Flume system is actually secure. This paper compares Flume with other recent DIFC systems like Asbestos, arguing that the latter is inherently susceptible to certain wide-bandwidth covert channels, and proving their absence in Flume by means of a noninterference proof in the communicating sequential processes formalism.","Internet, Linux, operating systems (computers), security of data, practical DIFC-based operating system, Flume system, decentralized information flow control, Linux operating system, Web applications, Asbestos, communicating sequential processes, noninterference proof, Operating systems, Information security, Data security, Kernel, Control systems, Linux, Dynamic programming, Communication system security, Privacy, Artificial intelligence, Information flow control, covert channels, noninterference, Communicating Sequential Processes,"
IEEE Security and Privacy 2009,"Native Client: A Sandbox for Portable, Untrusted x86 Native Code","This paper describes the design, implementation and evaluation of Native Client, a sandbox for untrusted x86 native code. Native Client aims to give browser-based applications the computational performance of native applications without compromising safety. Native Client uses software fault isolation and a secure runtime to direct system interaction and side effects through interfaces managed by Native Client. Native Client provides operating system portability for binary code while supporting performance-oriented features generally absent from Web application programming environments, such as thread support, instruction set extensions such as SSE, and use of compiler intrinsics and hand-coded assembler. We combine these properties in an open architecture that encourages community review and 3rd-party tools.","computer interfaces, Internet, online front-ends, security of data, software performance evaluation, Native client, sandbox, untrusted x86 native code, browser-based applications, software fault isolation, operating system portability, binary code, Web application programming environments, thread support, instruction set extensions, hand-coded assembler, open architecture, Application software, Security, Operating systems, Yarn, Assembly systems, Manuals, Java, High performance computing, Physics computing, Privacy, Security, World Wide Web,"
IEEE Security and Privacy 2009,Automatic Reverse Engineering of Malware Emulators,"Malware authors have recently begun using emulation technology to obfuscate their code. They convert native malware binaries into bytecode programs written in a randomly generated instruction set and paired with a native binary emulator that interprets the bytecode. No existing malware analysis can reliably reverse this obfuscation technique. In this paper, we present the first work in automatic reverse engineering of malware emulators. Our algorithms are based on dynamic analysis. We execute the emulated malware in a protected environment and record the entire x86 instruction trace generated by the emulator. We then use dynamic data-flow and taint analysis over the trace to identify data buffers containing the bytecode program and extract the syntactic and semantic information about the bytecode instruction set. With these analysis outputs, we are able to generate data structures, such as control-flow graphs, that provide the foundation for subsequent malware analysis. We implemented a proof-of-concept system called Rotalume and evaluated it using both legitimate programs and malware emulated by VMProtect and code virtualizer. The results show that Rotalume accurately reveals the syntax and semantics of emulated instruction sets and reconstructs execution paths of original programs from their bytecode representations.","data flow analysis, data structures, invasive software, reverse engineering, malware emulators, automatic reverse engineering, bytecode programs, emulation technology, x86 instruction trace, dynamic data flow analysis, dynamic taint analysis, bytecode instruction set, data structures, control flow graphs, proof-of-concept system, Rotalume, VMProtect, code virtualizer, Reverse engineering, Emulation, Algorithm design and analysis, Protection, Data analysis, Information analysis, Computer buffers, Data mining, Data structures, Instruction sets, Malware Analysis, Obfuscation, Emulation, Reverse-engineering,"
IEEE Security and Privacy 2009,Prospex: Protocol Specification Extraction,"Protocol reverse engineering is the process of extracting application-level specifications for network protocols. Such specifications are very useful in a number of security-related contexts, for example, to perform deep packet inspection and black-box fuzzing, or to quickly understand custom botnet command and control (C&C) channels. Since manual reverse engineering is a time-consuming and tedious process, a number of systems have been proposed that aim to automate this task. These systems either analyze network traffic directly or monitor the execution of the application that receives the protocol messages. While previous systems show that precise message formats can be extracted automatically, they do not provide a protocol specification.The reason is that they do not reverse engineer the protocol state machine. In this paper, we focus on closing this gap by presenting a system that is capable of automatically inferring state machines. This greatly enhances the results of automatic protocol reverse engineering, while further reducing the need for human interaction. We extend previous work that focuses on behavior-based message format extraction, and introduce techniques for identifying and clustering different types of messages not only based on their structure, but also according to the impact of each message on server behavior. Moreover, we present an algorithm for extracting the state machine. We have applied our techniques to a number of real-world protocols, including the command and control protocol used by a malicious bot. Our results demonstrate that we are able to extract format specifications for different types of messages and meaningful protocol state machines. We use these protocol specifications to automatically generate input for a stateful fuzzer, allowing us to discover security vulnerabilities in real-world applications.","formal specification, protocols, reverse engineering, security of data, protocol specification extraction, application-level specifications, network protocols, state machines, automatic protocol reverse engineering, behavior-based message format extraction, malicious bot, Protocols, Reverse engineering, Data mining, Command and control systems, Monitoring, Network servers, Telecommunication traffic, Inspection, Humans, Security,"
IEEE Security and Privacy 2009,Quantifying Information Leaks in Outbound Web Traffic,"As the Internet grows and network bandwidth continues to increase, administrators are faced with the task of keeping confidential information from leaving their networks. Todaypsilas network traffic is so voluminous that manual inspection would be unreasonably expensive. In response, researchers have created data loss prevention systems that check outgoing traffic for known confidential information. These systems stop naive adversaries from leaking data, but are fundamentally unable to identify encrypted or obfuscated information leaks. What remains is a high-capacity pipe for tunneling data to the Internet. We present an approach for quantifying information leak capacity in network traffic. Instead of trying to detect the presence of sensitive data-an impossible task in the general case--our goal is to measure and constrain its maximum volume. We take advantage of the insight that most network traffic is repeated or determined by external information, such as protocol specifications or messages sent by a server. By filtering this data, we can isolate and quantify true information flowing from a computer. In this paper, we present measurement algorithms for the Hypertext Transfer Protocol (HTTP), the main protocol for Web browsing. When applied to real Web browsing traffic, the algorithms were able to discount 98.5% of measured bytes and effectively isolate information leaks.","hypermedia, Internet, protocols, telecommunication security, telecommunication traffic, outbound Web browsing traffic, information leaks, Internet, network bandwidth, data loss prevention systems, network traffic, protocol specifications, hypertext transfer protocol, Telecommunication traffic, Protocols, IP networks, Bandwidth, Inspection, Cryptography, Tunneling, Internet, Volume measurement, Network servers, Information Leaks, HTTP, Web Traffic, Forensics, Intrusion Detection,"
IEEE Security and Privacy 2009,Automatic Discovery and Quantification of Information Leaks,"Information-flow analysis is a powerful technique for reasoning about the sensitive information exposed by a program during its execution. We present the first automatic method for information-flow analysis that discovers what information is leaked and computes its comprehensive quantitative interpretation. The leaked information is characterized by an equivalence relation on secret artifacts, and is represented by a logical assertion over the corresponding program variables. Our measurement procedure computes the number of discovered equivalence classes and their sizes. This provides a basis for computing a set of quantitative properties, which includes all established information-theoretic measures in quantitative information-flow. Our method exploits an inherent connection between formal models of qualitative information-flow and program verification techniques. We provide an implementation of our method that builds upon existing tools for program verification and information-theoretic analysis. Our experimental evaluation indicates the practical applicability of the presented method.","reasoning about programs, security of data, information leaks, information-flow analysis, comprehensive quantitative interpretation, program verification techniques, information-theoretic analysis, Information analysis, Entropy, Information security, Size measurement, Information theory, Communication channels, Channel capacity, Privacy, Throughput, Data flow computing, Information Flow, Information Theory, Program Analysis,"
IEEE Security and Privacy 2009,CLAMP: Practical Prevention of Large-Scale Data Leaks,"Providing online access to sensitive data makes Web servers lucrative targets for attackers. A compromise of any of the Web server's scripts, applications, or operating system can leak the sensitive data of millions of customers. Unfortunately, many systems for stopping data leaks require considerable effort from application developers, hindering their adoption. In this work, we investigate how such leaks can be prevented with minimal developer effort. We propose CLAMP, an architecture for preventing data leaks even in the presence of Web server compromises or SQL injection attacks. CLAMP protects sensitive data by enforcing strong access control on user data and by isolating code running on behalf of different users. By focusing on minimizing developer effort, we arrive at an architecture that allows developers to use familiar operating systems, servers, and scripting languages, while making relatively few changes to application code - less than 50 lines in our applications.","authorisation, operating systems (computers), SQL, Web services, large-scale data leaks prevention, CLAMP, Web servers, operating system, SQL injection attacks, access control, Web services, Clamps, Large-scale systems, Web server, Operating systems, Lamps, Application software, Programming profession, Data security, Service oriented architecture, Protection,"
IEEE Security and Privacy 2009,De-anonymizing Social Networks,"Operators of online social networks are increasingly sharing potentially sensitive information about users and their relationships with advertisers, application developers, and data-mining researchers. Privacy is typically protected by anonymization, i.e., removing names, addresses, etc.We present a framework for analyzing privacy and anonymity in social networks and develop a new re-identification algorithm targeting anonymized social-network graphs. To demonstrate its effectiveness on real-world networks, we show that a third of the users who can be verified to have accounts on both Twitter, a popular microblogging service, and Flickr, an online photo-sharing site, can be re-identified in the anonymous Twitter graph with only a 12% error rate.Our de-anonymization algorithm is based purely on the network topology, does not require creation of a large number of dummy ""sybil"" nodes, is robust to noise and all existing defenses, and works even when the overlap between the target network and the adversary's auxiliary information is small.","data mining, data privacy, graph theory, social networking (online), de-anonymizing social networks, data mining researchers, application developers, re-identification algorithm, anonymized social network graphs, network topology, Privacy, Facebook, Data privacy, Peer to peer computing, Companies, social networks, anonymity, privacy,"
IEEE Security and Privacy 2009,Privacy Weaknesses in Biometric Sketches,"The increasing use of biometrics has given rise to new privacy concerns. Biometric encryption systems have been proposed in order to alleviate such concerns: rather than comparing the biometric data directly, a key is derived from these data and subsequently knowledge of this key is proved. One specific application of biometric encryption is the use of biometric sketches: in this case biometric template data are protected with biometric encryption. We address the question whether one can undermine a user's privacy given access to biometrically encrypted documents, and more in particular, we examine if an attacker can determine whether two documents were encrypted using the same biometric. This is a particular concern for biometric sketches that are deployed in multiple locations: in one scenario the same biometric sketch is deployed everywhere; in a second scenario the same biometric data is protected with two different biometric sketches. We present attacks on template protection schemes that can be described as fuzzy sketches based on error-correcting codes. We demonstrate how to link and reverse protected templates produced by code-offset and bit-permutation sketches.","biometrics (access control), cryptography, data privacy, document handling, error correction codes, fuzzy set theory, biometric sketches, privacy weaknesses, biometric encryption systems, biometric template data, biometrically encrypted documents, fuzzy sketches, error-correcting codes, code-offset sketches, bit-permutation sketches, Privacy, Biometrics, Cryptography, Protection, Bioinformatics, Authentication, Data mining, Security, Error correction codes, Turbines,"
IEEE Security and Privacy 2009,The Mastermind Attack on Genomic Data,"In this paper, we study the degree to which a genomic string, Q, leaks details about itself any time it engages in comparison protocols with a genomic querier, Bob, even if those protocols are cryptographically guaranteed to produce no additional information other than the scores that assess the degree to which Q matches strings offered by Bob. We show that such scenarios allow Bob to play variants of the game of mastermind with Q so as to learn the complete identity of Q. We show that there are a number of efficient implementations for Bob to employ in these mastermind attacks, depending on knowledge he has about the structure of Q, which show how quickly he can determine Q. Indeed, we show that Bob can discover Q using a number of rounds of test comparisons that is much smaller than the length of Q, under various assumptions regarding the types of scores that are returned by the cryptographic protocols and whether he can use knowledge about the distribution that Q comes from, e.g., using public knowledge about the properties of human DNA. We also provide the results of an experimental study we performed on a database of mitochondrial DNA, showing the vulnerability of existing real-world DNA data to the mastermind attack.","biology computing, cryptographic protocols, DNA, mastermind attack, genomic data, cryptographic protocols, mitochondrial DNA database, genomic databases, Genomics, Bioinformatics, Sequences, Humans, DNA, Data privacy, Cryptographic protocols, Cryptography, Databases, Genetic mutations, mitochondrial DNA, genomic databases, privacy, mastermind, attacks,"
IEEE Security and Privacy 2009,A Logic of Secure Systems and its Application to Trusted Computing,"We present a logic for reasoning about properties of secure systems. The logic is built around a concurrent programming language with constructs for modeling machines with shared memory, a simple form of access control on memory, machine resets, cryptographic operations, network communication, and dynamically loading and executing unknown (and potentially untrusted) code. The adversary's capabilities are constrained by the system interface as defined in the programming model (leading to the name CSI -ADVERSARY). We develop a sound proof system for reasoning about programs without explicitly reasoning about adversary actions. We use the logic to characterize trusted computing primitives and prove code integrity and execution integrity properties of two remote attestation protocols. The proofs make precise assumptions needed for the security of these protocols and reveal an insecure interaction between the two protocols.","authorisation, cryptography, programming languages, protocols, reasoning about programs, trusted computing, secure systems, shared memory, concurrent programming language, access control, machine resets, cryptographic operations, network communication, CSI -ADVERSARY, reasoning about programs, remote attestation protocols, Computer applications, Logic programming, Security, Yarn, Computer languages, Protocols, Read-write memory, Cryptography, Access control, Virtual machine monitors, Trusted Computing, Remote Attestation, Logic of Secure Systems, Formal Reasoning,"
IEEE Security and Privacy 2009,Formally Certifying the Security of Digital Signature Schemes,"We present two machine-checked proofs of the existential unforgeability under adaptive chosen-message attacks of the full domain hash signature scheme. These proofs formalize the original argument of Bellare and Rogaway, and an optimal reduction by Coron that provides a tighter bound on the probability of a forgery. Both proofs are developed using CertiCrypt, a general framework to formalize exact security proofs of cryptographic systems in the computational model. Since CertiCrypt is implemented on top of theCoq proof assistant, the proofs are highly trustworthy and can beverified independently and fully automatically.","cryptography, digital signatures, digital signature schemes, machine-checked proofs, chosen-message attacks, full domain hash signature scheme, CertiCrypt, cryptographic systems, Security, Digital signatures, Cryptography, Forgery, Computational modeling, Privacy, Complexity theory, Polynomials, Standards development, Mathematical model, cryptography, cryptographic proofs, signature schemes, Full Domain Hash, Coq proof assistant, probabilistic progams, programming language, semantics, exact security, provable security, game-based proofs,"
IEEE Security and Privacy 2009,An Epistemic Approach to Coercion-Resistance for Electronic Voting Protocols,"Coercion resistance is an important and one of the most intricate security requirements of electronic voting protocols. Several definitions of coercion-resistance have been proposed in the literature,including definitions based on symbolic models.However, existing definitions in such models are rather restricted in their scope and quite complex.In this paper, we therefore propose a new definition of coercion resistance in a symbolic setting, based on an epistemic approach. Our definition is relatively simple and intuitive. It allows for a fine-grained formulation of coercion resistance and can be stated independently of a specific, symbolic protocol and adversary model. As a proof of concept,we apply our definition to three voting protocols. In particular, we carry out the first rigorous analysis of the recently proposed Civitas system. We precisely identify those conditions under which this system guarantees coercion resistance or fails to be coercion resistant. We also analyze protocols proposed by Lee et al. and Okamoto.","government data processing, protocols, security of data, electronic voting protocols, coercion-resistance, security requirements, epistemic approach, symbolic protocol, adversary model, Civitas system, Electronic voting, Security, Cryptographic protocols, Cryptography, Privacy, Concrete, Polynomials, Turing machines, security protocol analysis, electronic voting,"
IEEE Security and Privacy 2009,Sphinx: A Compact and Provably Secure Mix Format,"Sphinx is a cryptographic message format used to relay anonymized messages within a mix network. It is more compact than any comparable scheme, and supports a full set of security features: indistinguishable replies, hiding the path length and relay position, as well as providing unlinkability for each leg of the message's journey over the network. We prove the full cryptographic security of Sphinx in the random oracle model, and we describe how it can be used as an efficient drop-in replacement in deployed remailer systems.","cryptography, sphinx, cryptographic message format, mix format security, path length, relay position, random oracle model, remailer system, cryptographic security, Cryptography, Relays, Telecommunication traffic, Routing, Information security, Privacy, Information analysis, Protection, Data mining, Leg,"
IEEE Security and Privacy 2009,DSybil: Optimal Sybil-Resistance for Recommendation Systems,"Recommendation systems can be attacked in various ways, and the ultimate attack form is reached with a sybil attack, where the attacker creates a potentially unlimited number of sybil identities to vote. Defending against sybil attacks is often quite challenging, and the nature of recommendation systems makes it even harder. This paper presents DSybil, a novel defense for diminishing the influence of sybil identities in recommendation systems. DSybil provides strong provable guarantees that hold even under the worst-case attack and are optimal. DSybil can defend against an unlimited number of sybil identities over time. DSybil achieves its strong guarantees by i) exploiting the heavy-tail distribution of the typical voting behavior of the honest identities, and ii) carefully identifying whether the system is already getting ""enough help"" from the (weighted) voters already taken into account or whether more ""help"" is needed. Our evaluation shows that DSybil would continue to provide high-quality recommendations even when a million- node botnet uses an optimal strategy to launch a sybil attack.","information filters, security of data, recommendation systems, optimal sybil-resistance, sybil attack, DSybil, botnet, Voting, USA Councils, Casting, Social network services, National security, Privacy, Motion pictures, Books, Collaboration, Filtering, sybil attack, sybil identities, recommendation systems, DSybil, trust-based recommendation,"
IEEE Security and Privacy 2009,Fingerprinting Blank Paper Using Commodity Scanners,"We develop a novel technique for authenticating physical documents by using random, naturally occurring imperfections in paper texture. To this end, we devised a new method for measuring the three-dimensional surface of a paper without modifying the document in any way, using only a commodity scanner. From this physical feature, we generate a concise fingerprint that uniquely identifies the document. Our method is secure against counterfeiting, robust to harsh handling, and applicable even before any content is printed on a page. It has a wide range of applications, including detecting forged currency and tickets, authenticating passports, and halting counterfeit goods. On a more sinister note, document identification could be used to de-anonymize printed surveys and to compromise the secrecy of paper ballots.","document handling, security of data, fingerprinting blank paper, commodity scanners, physical documents authentication, paper texture, harsh handling, forged currency detection, de-anonymize printed surveys, document identification, paper ballots secrecy, Fingerprint recognition, Robustness, Surface texture, Counterfeiting, Authentication, Computer science, Printing, Forgery, Shape measurement, Computer security, fingerprinting, physical security, image procesing, biometrics,"
IEEE Security and Privacy 2009,Tempest in a Teapot: Compromising Reflections Revisited,"Reflecting objects such as tea pots and glasses, but also diffusely reflecting objects such as a user's shirt, can be used to spy on confidential data displayed on a monitor. First, we show how reflections in the user's eye can be exploited for spying on confidential data. Second, we investigate to what extent monitor images can be reconstructed from the diffuse reflections on a wall or the user's clothes, and provide information-theoretic bounds limiting this type of attack. Third, we evaluate the effectiveness of several countermeasures. This substantially improves previous work (Backes et al., IEEE Symposium on Security & Privacy, 2008).","reflection, security of data, reflecting objects, tea pots, glasses, confidential data, image reconstruction, diffuse reflections, information-theoretic bounds, Optical reflection, Computerized monitoring, Image reconstruction, Telescopes, Electromagnetic reflection, Humans, Focusing, Optical diffraction, Optical sensors, Apertures,"
IEEE Security and Privacy 2009,Blueprint: Robust Prevention of Cross-site Scripting Attacks for Existing Browsers,"As social networking sites proliferate across the World Wide Web, complex user-created HTML content is rapidly becoming the norm rather than the exception. User-created Web content is a notorious vector for cross-site scripting (XSS) attacks that target Web sites and confidential user data. In this threat climate, mechanisms that render web applications immune to XSS attacks have been of recent research interest.A challenge for these security mechanisms is enabling Web applications to accept complex HTML input from users, while disallowing malicious script content. This challenge is made difficult by anomalous Web browser behaviors, which are often used as vectors for successful XSS attacks.Motivated by this problem, we present a new XSS defense strategy designed to be effective in widely deployed existing Web browsers, despite anomalous browser behavior. Our approach seeks to minimize trust placed on browsers for interpreting untrusted content. We implemented this approach in a tool called Blueprint that was integrated with several popular Web applications. We evaluated Blueprint against a barrage of stress tests that demonstrate strong resistance to attacks, excellent compatibility with Web browsers and reasonable performance overheads.","hypermedia markup languages, Internet, online front-ends, security of data, social networking (online), Blueprint, cross-site scripting attacks, social networking sites, World Wide Web, user-created HTML content, Web sites, threat climate, anomalous Web browser behaviors, XSS defense strategy, Robustness, HTML, Web sites, Collaboration, Internet, Social network services, Information filtering, Information filters, Information services, Data security, XSS, Web application security, unauthorized code execution, malicious code injection, input validation, document structural integrity, isolation, browser security, browser flaws,"
IEEE Security and Privacy 2009,Pretty-Bad-Proxy: An Overlooked Adversary in Browsers' HTTPS Deployments,"HTTPS is designed to provide secure Web communications over insecure networks. The protocol itself has been rigorously designed and evaluated by assuming the network as an adversary. This paper is motivated by our curiosity about whether such an adversary has been carefully examined when HTTPS is integrated into the browser/Web systems. We focus on a specific adversary named ldquopretty-bad-proxyrdquo (PBP). PBP is a malicious proxy targeting browserspsila rendering modules above the HTTP/HTTPS layer. It attempts to break the end-to-end security guarantees of HTTPS without breaking any cryptographic scheme. We discovered a set of vulnerabilities exploitable by a PBP: in many realistic network environments where attackers can sniff the browser traffic, they can steal sensitive data from an HTTPS server, fake an HTTPS page and impersonate an authenticated user to access an HTTPS server. These vulnerabilities reflect the neglects in the design of modern browsers - they affect multiple major browsers and a large number of Web sites. We believe that the PBP adversary has not been rigorously examined in the browser/Web industry. The vendors of the affected browsers have all confirmed the vulnerabilities reported in this paper. Most of them have patched or planned on patching their browsers. We believe the attack scenarios described in this paper may only be a subset of the vulnerabilities under PBP. Thus further (and more rigorous) evaluations of the HTTPS deployments in browsers appear to be necessary.","cryptography, transport protocols, Web sites, browsers HTTPS deployments, pretty-bad-proxy, secure Web communications, browser-Web systems, malicious proxy, cryptographic scheme, Web sites, Web server, Cryptography, Network servers, USA Councils, Telecommunication traffic, Protocols, Data security, HTML, Engines, Privacy, pretty-bad-proxy, HTTPS deployment, browser security,"
IEEE Security and Privacy 2009,"Secure Content Sniffing for Web Browsers, or How to Stop Papers from Reviewing Themselves","Cross-site scripting defenses often focus on HTML documents, neglecting attacks involving the browser's content-sniffing algorithm, which can treat non-HTML content as HTML. Web applications, such as the one that manages this conference, must defend themselves against these attacks or risk authors uploading malicious papers that automatically submit stellar self-reviews. In this paper, we formulate content-sniffing XSS attacks and defenses. We study content-sniffing XSS attacks systematically by constructing high-fidelity models of the content-sniffing algorithms used by four major browsers. We compare these models with Web site content filtering policies to construct attacks. To defend against these attacks, we propose and implement a principled content-sniffing algorithm that provides security while maintaining compatibility. Our principles have been adopted, in part, by Internet Explorer 8 and, in full, by Google Chrome and the HTML 5 working group.","hypermedia markup languages, online front-ends, security of data, Web browsers, secure content sniffing, cross-site scripting defenses, HTML documents, content-sniffing XSS attacks, Web site content filtering policies, Internet Explorer 8, Google Chrome, HTML 5 working group, HTML, Security, Internet, Page description languages, Wikipedia, Conference management, Privacy, Algorithm design and analysis, Risk management, Information filtering, Web, Security, Cross-Site Scripting, Content-Sniffing, MIME,"
IEEE Security and Privacy 2009,It's No Secret. Measuring the Security and Reliability of Authentication via “Secret” Questions,"All four of the most popular webmail providers - AOL, Google, Microsoft, and Yahoo! - rely on personal questions as the secondary authentication secrets used to reset account passwords. The security of these questions has received limited formal scrutiny, almost all of which predates webmail. We ran a user study to measure the reliability and security of the questions used by all four webmail providers. We asked participants to answer these questions and then asked their acquaintances to guess their answers. Acquaintances with whom participants reported being unwilling to share their webmail passwords were able to guess 17% of their answers. Participants forgot 20% of their own answers within six months. What's more, 13% of answers could be guessed within five attempts by guessing the most popular answers of other participants, though this weakness is partially attributable to the geographic homogeneity of our participant pool.","Internet, security of data, authentication reliability, secret questions, webmail providers, AOL, Google, Microsoft, Yahoo, limited formal scrutiny, geographic homogeneity, Security, Authentication, Laboratories, Privacy, Brushes, Radio access networks, Web services, Electronic mail, Postal services, Statistics, Authentication,"
IEEE Security and Privacy 2009,Password Cracking Using Probabilistic Context-Free Grammars,"Choosing the most effective word-mangling rules to use when performing a dictionary-based password cracking attack can be a difficult task. In this paper we discuss a new method that generates password structures in highest probability order. We first automatically create a probabilistic context-free grammar based upon a training set of previously disclosed passwords. This grammar then allows us to generate word-mangling rules, and from them, password guesses to be used in password cracking. We will also show that this approach seems to provide a more effective way to crack passwords as compared to traditional methods by testing our tools and techniques on real password sets. In one series of experiments, training on a set of disclosed passwords, our approach was able to crack 28% to 129% more passwords than John the Ripper, a publicly available standard password cracking program.","computer crime, context-free grammars, dictionaries, probability, dictionary-based password cracking attack, probabilistic context-free grammars, word-mangling rules, password cracking program, data security, computer crime, Computer science, Testing, Computer security, Data security, Hardware, Dictionaries, Privacy, USA Councils, Computer crime, Access control, Computer security, Data security, Computer crime,"
